package gbl

/*
	CREDIT:
	https://blog.gopheracademy.com/advent-2014/parsers-lexers/
*/

import (
	"bufio"
	"bytes"
	"io"
	"strings"
	"unicode"
)

// Token is a lexical token generated by the scanner.
type Token string

// A list of available tokens.
const (
	tokenInvalid      = "Invalid"
	tokenEndOfFile    = "EndOfFile"
	tokenWhitespace   = "Whitespace"
	tokenBracketLeft  = "BracketLeft"
	tokenBracketRight = "BracketRight"
	tokenParenLeft    = "ParenLeft"
	tokenParenRight   = "ParenRight"
	tokenComma        = "Comma"
	tokenColon        = "Colon"
	tokenAssign       = "Assign"
	tokenLiteral      = "Literal"
	tokenIdentifier   = "Identifier"
	tokenComposite    = "Composite"
	tokenDecorator    = "Decorator"
	tokenCondition    = "Condition"
	tokenAction       = "Action"
)

// map from keyword to token
var kw2tok = map[string]Token{
	"COMPOSITE": tokenComposite,
	"+":         tokenComposite,
	"DECORATOR": tokenDecorator,
	"*":         tokenDecorator,
	"ACTION":    tokenAction,
	"!":         tokenAction,
	"CONDITION": tokenCondition,
	"?":         tokenCondition,
}

const eof = rune(0)

// IsEOF returns true if tok is an EOF token.
func (tok Token) IsEOF() bool {
	return tok == tokenEndOfFile
}

// IsWhitespace returns true if tok is a whitespace token.
func (tok Token) IsWhitespace() bool {
	return tok == tokenWhitespace
}

// IsInvalid returns true if tok is an invalid token.
func (tok Token) IsInvalid() bool {
	return tok == tokenInvalid
}

func isKeyword(lit string) bool {
	_, ok := kw2tok[lit]
	return ok
}

var (
	isWhitespace = unicode.IsSpace
	isLetter     = unicode.IsLetter
	isDigit      = unicode.IsDigit
)

// Scanner ...
type Scanner struct {
	r *bufio.Reader
}

// NewScanner returns a scanner that reads from r.
func NewScanner(r io.Reader) *Scanner {
	return &Scanner{r: bufio.NewReader(r)}
}

func (s *Scanner) read() rune {
	ch, _, err := s.r.ReadRune()
	if err != nil {
		return eof
	}
	return ch
}

func (s *Scanner) unread() {
	_ = s.r.UnreadRune()
}

// Scan scans one token, and returns the token and the scanned string.
func (s *Scanner) Scan() (tok Token, lit string) {
	ch := s.read()

	if isWhitespace(ch) {
		s.unread()
		return s.scanWhitespace()

	} else if isLetter(ch) {
		s.unread()
		return s.scanWord()

	} else if ch == '#' {
		return s.scanLiteral()
	}

	if tok, ok := runes[ch]; ok {
		return tok, string(ch)
	}
	return tokenInvalid, string(ch)
}

var runes = map[rune]Token{
	eof: tokenEndOfFile,
	'!': tokenAction,
	'?': tokenCondition,
	'*': tokenDecorator,
	'+': tokenComposite,
	'{': tokenBracketLeft,
	'}': tokenBracketRight,
	'(': tokenParenLeft,
	')': tokenParenRight,
	':': tokenColon,
	',': tokenComma,
	'=': tokenAssign,
}

func (s *Scanner) scanWhitespace() (tok Token, lit string) {
	var buf bytes.Buffer
	buf.WriteRune(s.read())
	for {
		if ch := s.read(); ch == eof {
			break
		} else if !isWhitespace(ch) {
			s.unread()
			break
		} else {
			buf.WriteRune(ch)
		}
	}
	return tokenWhitespace, buf.String()
}

func (s *Scanner) scanLiteral() (tok Token, lit string) {
	var buf bytes.Buffer
	buf.WriteRune(s.read())
	for {
		if ch := s.read(); ch == eof {
			break
		} else if !validLiteralRune(ch) {
			s.unread()
			break
		} else {
			_, _ = buf.WriteRune(ch)
		}
	}
	return tokenLiteral, buf.String()
}

func (s *Scanner) scanWord() (tok Token, lit string) {
	var buf bytes.Buffer
	buf.WriteRune(s.read())
	for {
		if ch := s.read(); ch == eof {
			break
		} else if !validWordRune(ch) {
			s.unread()
			break
		} else {
			_, _ = buf.WriteRune(ch)
		}
	}

	// If the string matches a keyword then return that keyword.
	lit = strings.ToUpper(buf.String())
	if tok, ok := kw2tok[lit]; ok {
		return tok, lit
	}

	// Otherwise return as a regular identifier.
	return tokenIdentifier, buf.String()
}

func validWordRune(ch rune) bool {
	return isLetter(ch) || isDigit(ch) || ch == '_' || ch == '.'
}

func validLiteralRune(ch rune) bool {
	return isDigit(ch)
}
